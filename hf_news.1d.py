#!/usr/bin/env python3
# <xbar.title>Hugging Face Datasets</xbar.title>
# <xbar.version>v2.1</xbar.version>
# <xbar.author>MichaelPeng</xbar.author>
# <xbar.desc>Track new datasets on Hugging Face Hub with stats</xbar.desc>
# <xbar.dependencies>python3,requests</xbar.dependencies>

import requests
import sys
import json
from datetime import datetime, timedelta, timezone

# Configuration
BASE_URL = "https://huggingface.co/api/datasets"
DAYS_TO_FETCH = 7  # æ˜¾ç¤ºæœ€è¿‘7å¤©çš„æ•°æ®é›†
LIMIT = 1000
MAX_DISPLAY = 20  # èœå•ä¸­æœ€å¤šæ˜¾ç¤ºçš„æ•°æ®é›†æ•°é‡

# å›¾æ ‡å’Œé¢œè‰²é…ç½®
ICONS = {
    'new': 'ğŸ†•',
    'hot': 'ğŸ”¥',
    'trending': 'ğŸ“ˆ',
    'dataset': 'ğŸ“Š',
    'downloads': 'â¬‡ï¸',
    'likes': 'â¤ï¸',
    'author': 'ğŸ‘¤',
    'time': 'ğŸ•',
    'size': 'ğŸ’¾',
    'tag': 'ğŸ·ï¸',
    'info': 'â„¹ï¸',
    'link': 'ğŸ”—',
    'refresh': 'ğŸ”„',
    'browse': 'ğŸŒ',
    'private': 'ğŸ”’',
    'public': 'ğŸ”“',
    'star': 'â­',
    'fork': 'ğŸ”±'
}

COLORS = {
    'title': '#000000',
    'subtitle': '#666666',
    'accent': '#FF9800',
    'success': '#4CAF50',
    'error': '#F44336',
    'link': '#2196F3',
    'muted': '#9E9E9E',
    'likes': '#E91E63',
    'downloads': '#00BCD4'
}


def get_recent_datasets(n_days):
    """è·å–æœ€è¿‘ n å¤©çš„æ•°æ®é›†"""
    params = {
        "limit": LIMIT,
        "sort": "createdAt",
        "direction": "-1",
        "full": "true",
    }
    
    cutoff_date = datetime.now(timezone.utc) - timedelta(days=n_days)
    datasets = []
    url = BASE_URL
    
    try:
        while url:
            r = requests.get(url, params=params, timeout=10)
            r.raise_for_status()
            data = r.json()
            
            stop = False
            for ds in data:
                if "createdAt" in ds:
                    created = datetime.fromisoformat(ds["createdAt"].replace("Z", "+00:00"))
                    if created >= cutoff_date:
                        datasets.append(ds)
                    else:
                        stop = True
                        break
            
            if stop:
                break
            
            # ç¿»é¡µå¤„ç†
            if "Link" in r.headers and 'rel="next"' in r.headers["Link"]:
                url = r.headers["Link"].split(";")[0].strip("<>")
                params = {}
            else:
                url = None
                
    except Exception as e:
        return None, str(e)
    
    return datasets, None


def format_time_ago(created_str):
    """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º"""
    try:
        created = datetime.fromisoformat(created_str.replace("Z", "+00:00"))
        now = datetime.now(timezone.utc)
        delta = now - created
        
        hours = delta.total_seconds() / 3600
        if hours < 1:
            minutes = int(delta.total_seconds() / 60)
            return f"{minutes} minutes ago"
        elif hours < 24:
            return f"{int(hours)} hours ago"
        elif delta.days == 1:
            return "1 day ago"
        elif delta.days < 7:
            return f"{delta.days} days ago"
        elif delta.days < 30:
            weeks = delta.days // 7
            return f"{weeks} week{'s' if weeks > 1 else ''} ago"
        else:
            return created.strftime("%Y-%m-%d")
    except:
        return "Unknown"


def format_time_short(created_str):
    """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤ºï¼ˆç®€çŸ­ç‰ˆï¼‰"""
    try:
        created = datetime.fromisoformat(created_str.replace("Z", "+00:00"))
        now = datetime.now(timezone.utc)
        delta = now - created
        
        hours = delta.total_seconds() / 3600
        if hours < 1:
            minutes = int(delta.total_seconds() / 60)
            return f"{minutes}m"
        elif hours < 24:
            return f"{int(hours)}h"
        else:
            return f"{delta.days}d"
    except:
        return ""


def sanitize_text(text, max_length=50):
    """æ¸…ç†æ–‡æœ¬ç”¨äº xbar æ˜¾ç¤º"""
    if not text:
        return ""
    text = str(text).replace("|", "â€“").replace("\n", " ")
    if len(text) > max_length:
        text = text[:max_length-3] + "..."
    return text


def format_number(num):
    """æ ¼å¼åŒ–æ•°å­—"""
    if num is None:
        return "0"
    if num >= 1000000:
        return f"{num/1000000:.1f}M"
    elif num >= 1000:
        return f"{num/1000:.1f}K"
    else:
        return str(num)


def get_dataset_emoji(dataset):
    """æ ¹æ®æ•°æ®é›†ç‰¹å¾è¿”å›åˆé€‚çš„ emoji"""
    likes = dataset.get("likes", 0)
    downloads = dataset.get("downloads", 0)
    created_str = dataset.get("createdAt", "")
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°æ•°æ®é›†ï¼ˆ24å°æ—¶å†…ï¼‰
    try:
        created = datetime.fromisoformat(created_str.replace("Z", "+00:00"))
        now = datetime.now(timezone.utc)
        hours_old = (now - created).total_seconds() / 3600
        
        if hours_old < 24:
            return ICONS['new']
        elif likes > 10 or downloads > 100:
            return ICONS['hot']
        elif likes > 5 or downloads > 50:
            return ICONS['trending']
    except:
        pass
    
    return ICONS['dataset']


def pad_string(text, length):
    """å¡«å……å­—ç¬¦ä¸²åˆ°æŒ‡å®šé•¿åº¦ï¼ˆæ”¯æŒä¸­æ–‡ï¼‰"""
    text_len = len(text.encode('gbk', errors='ignore'))
    if text_len < length:
        return text + ' ' * (length - text_len)
    return text


def format_stats_compact(likes, downloads):
    """ç´§å‡‘æ ¼å¼åŒ–ç»Ÿè®¡æ•°æ®"""
    parts = []
    if likes > 0:
        parts.append(f"â¤ï¸{format_number(likes)}")
    if downloads > 0:
        parts.append(f"â¬‡ï¸{format_number(downloads)}")
    
    if not parts:
        return "â€”"
    
    return " ".join(parts)


def print_dataset_details(dataset):
    """æ‰“å°æ•°æ®é›†è¯¦ç»†ä¿¡æ¯çš„å­èœå•"""
    dataset_id = dataset.get("id", "Unknown")
    dataset_url = f"https://huggingface.co/datasets/{dataset_id}"
    
    # åŸºæœ¬ä¿¡æ¯
    print(f"--{ICONS['info']} Dataset Details | color={COLORS['muted']}")
    print(f"----Repository: {dataset_id} | font=Monaco size=11")
    print(f"----Created: {format_time_ago(dataset.get('createdAt', ''))} | font=Monaco size=11")
    
    # æ˜¯å¦ç§æœ‰
    is_private = dataset.get("private", False)
    print(f"----Status: {ICONS['private' if is_private else 'public']} {'Private' if is_private else 'Public'} | font=Monaco size=11")
    
    # æ ‡ç­¾
    tags = dataset.get("tags", [])
    if tags:
        print(f"--{ICONS['tag']} Tags ({len(tags)}) | color={COLORS['muted']}")
        for tag in tags[:10]:  # æ˜¾ç¤ºæœ€å¤š10ä¸ªæ ‡ç­¾
            print(f"----{sanitize_text(tag, 30)} | font=Monaco size=11")
    
    # æè¿°
    description = dataset.get("description", "")
    if description:
        print(f"--{ICONS['info']} Description | color={COLORS['muted']}")
        # å°†æè¿°åˆ†æˆå¤šè¡Œæ˜¾ç¤º
        desc_lines = sanitize_text(description, 300).split(". ")
        for line in desc_lines[:5]:  # æ˜¾ç¤ºæœ€å¤š5è¡Œ
            if line.strip():
                print(f"----{line.strip()}. | font=Monaco size=11")
    
    # å¿«æ·æ“ä½œ
    print(f"--{ICONS['link']} Actions | color={COLORS['muted']}")
    print(f"----Open in Browser | href={dataset_url} color={COLORS['link']}")
    print(f"----View Dataset Viewer | href={dataset_url}/viewer color={COLORS['link']}")
    print(f"----View Files | href={dataset_url}/tree/main color={COLORS['link']}")
    print(f"----Copy URL | bash='echo \"{dataset_url}\" | pbcopy' terminal=false")
    print(f"----Copy ID | bash='echo \"{dataset_id}\" | pbcopy' terminal=false")


def categorize_datasets(datasets):
    """å°†æ•°æ®é›†æŒ‰æ—¶é—´åˆ†ç±»"""
    categories = {
        'today': [],
        'yesterday': [],
        'this_week': [],
        'older': []
    }
    
    now = datetime.now(timezone.utc)
    today = now.date()
    yesterday = today - timedelta(days=1)
    week_ago = today - timedelta(days=7)
    
    for ds in datasets:
        created_str = ds.get("createdAt", "")
        try:
            created = datetime.fromisoformat(created_str.replace("Z", "+00:00"))
            created_date = created.date()
            
            if created_date == today:
                categories['today'].append(ds)
            elif created_date == yesterday:
                categories['yesterday'].append(ds)
            elif created_date > week_ago:
                categories['this_week'].append(ds)
            else:
                categories['older'].append(ds)
        except:
            categories['older'].append(ds)
    
    return categories


def main():
    datasets, error = get_recent_datasets(DAYS_TO_FETCH)
    
    if error:
        print(f"{ICONS['dataset']} Error")
        print("---")
        print(f"Failed to fetch datasets | color={COLORS['error']}")
        print(f"Error: {error} | color={COLORS['error']} font=Monaco size=11")
        print("---")
        print(f"{ICONS['refresh']} Retry | refresh=true")
        sys.exit(1)
    
    if not datasets:
        print(f"{ICONS['dataset']} No new datasets")
        print("---")
        print(f"No datasets in last {DAYS_TO_FETCH} days | color={COLORS['muted']}")
        print(f"{ICONS['refresh']} Refresh | refresh=true")
        return
    
    # æŒ‰æ—¶é—´åˆ†ç±»æ•°æ®é›†
    categorized = categorize_datasets(datasets)
    
    # æ˜¾ç¤ºèœå•æ æ ‡é¢˜
    total_count = len(datasets)
    today_count = len(categorized['today'])
    
    if today_count > 0:
        print(f"{ICONS['new']} {today_count} today â€¢ {total_count} total")
    else:
        print(f"{ICONS['dataset']} {total_count} datasets")
    
    print("---")
    
    # æ·»åŠ ç»Ÿè®¡æ ‡é¢˜æ 
    print(f"DATASETS {'Â·'*20} STATS {'Â·'*8} TIME | font=Monaco size=10 color={COLORS['muted']}")
    print("---")
    
    # æ˜¾ç¤ºä¸åŒæ—¶é—´æ®µçš„æ•°æ®é›†
    display_count = 0
    
    # ä»Šå¤©çš„æ•°æ®é›†
    if categorized['today']:
        print(f"{ICONS['new']} Today â€” {len(categorized['today'])} datasets | color={COLORS['accent']}")
        for ds in sorted(categorized['today'], key=lambda x: x.get('likes', 0), reverse=True)[:7]:
            display_count += 1
            print_dataset_item(ds, display_count)
        if categorized['today']:
            print("---")
    
    # æ˜¨å¤©çš„æ•°æ®é›†
    if categorized['yesterday'] and display_count < MAX_DISPLAY:
        print(f"{ICONS['time']} Yesterday â€” {len(categorized['yesterday'])} datasets | color={COLORS['subtitle']}")
        for ds in sorted(categorized['yesterday'], key=lambda x: x.get('likes', 0), reverse=True)[:6]:
            display_count += 1
            if display_count > MAX_DISPLAY:
                break
            print_dataset_item(ds, display_count)
        if categorized['yesterday']:
            print("---")
    
    # æœ¬å‘¨çš„æ•°æ®é›†
    if categorized['this_week'] and display_count < MAX_DISPLAY:
        print(f"{ICONS['trending']} This Week â€” {len(categorized['this_week'])} datasets | color={COLORS['subtitle']}")
        for ds in sorted(categorized['this_week'], key=lambda x: x.get('likes', 0), reverse=True)[:10]:
            display_count += 1
            if display_count > MAX_DISPLAY:
                break
            print_dataset_item(ds, display_count)
    
    # åº•éƒ¨èœå•
    print("---")
    print(f"{ICONS['refresh']} Refresh | refresh=true")
    print(f"{ICONS['browse']} Browse All Datasets | href=https://huggingface.co/datasets color={COLORS['link']}")
    print(f"{ICONS['trending']} Trending Datasets | href=https://huggingface.co/datasets?sort=trending color={COLORS['link']}")
    print("---")
    
    # æ€»ç»“ç»Ÿè®¡
    total_likes = sum(ds.get('likes', 0) for ds in datasets)
    total_downloads = sum(ds.get('downloads', 0) for ds in datasets)
    print(f"Summary: {total_count} datasets â€¢ {format_number(total_likes)} likes â€¢ {format_number(total_downloads)} downloads | color={COLORS['muted']} size=10")
    print(f"Last update: {datetime.now().strftime('%Y-%m-%d %H:%M')} | color={COLORS['muted']} size=10")


def print_dataset_item(ds, number):
    """æ‰“å°å•ä¸ªæ•°æ®é›†é¡¹ç›®ï¼Œåœ¨ä¸»èœå•æ˜¾ç¤ºç»Ÿè®¡æ•°æ®"""
    dataset_id = ds.get("id", "Unknown")
    dataset_name = dataset_id.split("/")[-1] if "/" in dataset_id else dataset_id
    author = dataset_id.split("/")[0] if "/" in dataset_id else ""
    
    # è·å–ç»Ÿè®¡æ•°æ®
    downloads = ds.get("downloads", 0)
    likes = ds.get("likes", 0)
    time_str = format_time_short(ds.get("createdAt", ""))
    
    # è·å–åˆé€‚çš„emoji
    emoji = get_dataset_emoji(ds)
    
    # æ ¼å¼åŒ–åç§°ï¼ˆå›ºå®šé•¿åº¦ï¼‰
    name_display = sanitize_text(dataset_name, 25)
    author_display = sanitize_text(author, 15) if author else "anonymous"
    
    # æ„å»ºæ˜¾ç¤ºæ–‡æœ¬ï¼Œä½¿ç”¨å›ºå®šå®½åº¦å¸ƒå±€
    # ä½¿ç”¨ | åˆ†éš”ä¸åŒéƒ¨åˆ†ï¼Œè®©æ˜¾ç¤ºæ›´æ•´é½
    dataset_url = f"https://huggingface.co/datasets/{dataset_id}"
    
    # ä¸»æ˜¾ç¤ºè¡Œ - åŒ…å«æ‰€æœ‰ä¿¡æ¯
    # æ ¼å¼: [emoji] åç§° | ä½œè€… | ç»Ÿè®¡ | æ—¶é—´
    name_part = f"{emoji} {name_display:<25}"
    author_part = f"@{author_display:<15}"
    
    # ç»Ÿè®¡ä¿¡æ¯éƒ¨åˆ†
    stats_parts = []
    if likes > 0:
        stats_parts.append(f"â¤ï¸ {format_number(likes):>5}")
    else:
        stats_parts.append(f"{'':>7}")  # å ä½
        
    if downloads > 0:
        stats_parts.append(f"â¬‡ï¸ {format_number(downloads):>5}")
    else:
        stats_parts.append(f"{'':>7}")  # å ä½
    
    stats_display = " ".join(stats_parts)
    
    # æ—¶é—´éƒ¨åˆ†
    time_display = f"[{time_str:>3}]" if time_str else "[   ]"
    
    # ç»„åˆæ‰€æœ‰éƒ¨åˆ†
    full_display = f"{name_part} â€¢ {author_part} â€¢ {stats_display} â€¢ {time_display}"
    
    # ä¸»èœå•é¡¹ - ä½¿ç”¨ç­‰å®½å­—ä½“
    print(f"{full_display} | href={dataset_url} font=Monaco size=12")
    
    # æ·»åŠ äº¤æ›¿æ˜¾ç¤ºçš„è¯¦ç»†ä¿¡æ¯ï¼ˆæŒ‰ä½Optioné”®æŸ¥çœ‹ï¼‰
    if author:
        detail_text = f"  ğŸ“ {dataset_id} - Created {format_time_ago(ds.get('createdAt', ''))}"
        print(f"{detail_text} | alternate=true font=Monaco size=11 color={COLORS['subtitle']}")
    
    # æ·»åŠ å­èœå•è¯¦ç»†ä¿¡æ¯
    print_dataset_details(ds)


def print_compact_header():
    """æ‰“å°ç´§å‡‘çš„è¡¨å¤´"""
    header = "Dataset Name" + " " * 15 + "Author" + " " * 10 + "Stats" + " " * 10 + "Time"
    print(f"{header} | font=Monaco size=10 color={COLORS['muted']}")
    print(f"{'â”€' * 70} | font=Monaco size=10 color={COLORS['muted']}")


if __name__ == "__main__":
    main()
